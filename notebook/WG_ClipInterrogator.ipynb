{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKZbhjMfMEjm"
      },
      "source": [
        "### *La Maquina que ve @ ETSAM - November 2024*\n",
        "#**WHAT - Text-to-Image Description with Clip Interrogator**\n",
        "*Iacopo Neri (iacopo.neri@uzh.ch) -- IAAC Faculty & MaCT Computational Lead (Spain) // Digital Visual Studies, University of Zurich (Switzerland)*\n",
        "\n",
        "*Dar√¨o Negueruela del Castillo (iacopo.neri@uzh.ch) -- Digital Visual Studies, University of Zurich (Switzerland)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDsu8DTSMEjo"
      },
      "source": [
        "The following script takes extensive inspiration from the original [CLIP Interrogator 2.4 Colab example](https://colab.research.google.com/github/pharmapsychotic/clip-interrogator/blob/main/clip_interrogator.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngUNF7VcMEjp"
      },
      "source": [
        "# Define functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "aP9FjmWxtLKJ"
      },
      "outputs": [],
      "source": [
        "#@title Check GPU\n",
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xpPKQR40qvz2"
      },
      "outputs": [],
      "source": [
        "#@title Setup\n",
        "import os, subprocess\n",
        "\n",
        "def setup():\n",
        "    install_cmds = [\n",
        "        ['pip', 'install', 'gradio'],\n",
        "        ['pip', 'install', 'open_clip_torch'],\n",
        "        ['pip', 'install', 'clip-interrogator'],\n",
        "    ]\n",
        "    for cmd in install_cmds:\n",
        "        print(subprocess.run(cmd, stdout=subprocess.PIPE).stdout.decode('utf-8'))\n",
        "\n",
        "setup()\n",
        "\n",
        "\n",
        "caption_model_name = 'blip-large' #@param [\"blip-base\", \"blip-large\", \"git-large-coco\"]\n",
        "clip_model_name = 'ViT-L-14/openai' #@param [\"ViT-L-14/openai\", \"ViT-H-14/laion2b_s32b_b79k\"]\n",
        "\n",
        "import gradio as gr\n",
        "from clip_interrogator import Config, Interrogator\n",
        "\n",
        "config = Config()\n",
        "config.clip_model_name = clip_model_name\n",
        "config.caption_model_name = caption_model_name\n",
        "ci = Interrogator(config)\n",
        "\n",
        "def image_analysis(image):\n",
        "    image = image.convert('RGB')\n",
        "    image_features = ci.image_to_features(image)\n",
        "\n",
        "    top_mediums = ci.mediums.rank(image_features, 5)\n",
        "    top_artists = ci.artists.rank(image_features, 5)\n",
        "    top_movements = ci.movements.rank(image_features, 5)\n",
        "    top_trendings = ci.trendings.rank(image_features, 5)\n",
        "    top_flavors = ci.flavors.rank(image_features, 5)\n",
        "\n",
        "    medium_ranks = {medium: sim for medium, sim in zip(top_mediums, ci.similarities(image_features, top_mediums))}\n",
        "    artist_ranks = {artist: sim for artist, sim in zip(top_artists, ci.similarities(image_features, top_artists))}\n",
        "    movement_ranks = {movement: sim for movement, sim in zip(top_movements, ci.similarities(image_features, top_movements))}\n",
        "    trending_ranks = {trending: sim for trending, sim in zip(top_trendings, ci.similarities(image_features, top_trendings))}\n",
        "    flavor_ranks = {flavor: sim for flavor, sim in zip(top_flavors, ci.similarities(image_features, top_flavors))}\n",
        "\n",
        "    return medium_ranks, artist_ranks, movement_ranks, trending_ranks, flavor_ranks\n",
        "\n",
        "def image_to_prompt(image, mode):\n",
        "    ci.config.chunk_size = 2048 if ci.config.clip_model_name == \"ViT-L-14/openai\" else 1024\n",
        "    ci.config.flavor_intermediate_count = 2048 if ci.config.clip_model_name == \"ViT-L-14/openai\" else 1024\n",
        "    image = image.convert('RGB')\n",
        "    if mode == 'best':\n",
        "        return ci.interrogate(image)\n",
        "    elif mode == 'classic':\n",
        "        return ci.interrogate_classic(image)\n",
        "    elif mode == 'fast':\n",
        "        return ci.interrogate_fast(image)\n",
        "    elif mode == 'negative':\n",
        "        return ci.interrogate_negative(image)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTEQ2vswMEjq"
      },
      "source": [
        "# Run UI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Pf6qkFG6MPRj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def prompt_tab():\n",
        "    with gr.Column():\n",
        "        with gr.Row():\n",
        "            image = gr.Image(type='pil', label=\"Image\")\n",
        "            with gr.Column():\n",
        "                mode = gr.Radio(['best', 'fast', 'classic', 'negative'], label='Mode', value='best')\n",
        "        prompt = gr.Textbox(label=\"Prompt\")\n",
        "    button = gr.Button(\"Generate prompt\")\n",
        "    button.click(image_to_prompt, inputs=[image, mode], outputs=prompt)\n",
        "\n",
        "def analyze_tab():\n",
        "    with gr.Column():\n",
        "        with gr.Row():\n",
        "            image = gr.Image(type='pil', label=\"Image\")\n",
        "        with gr.Row():\n",
        "            medium = gr.Label(label=\"Medium\", num_top_classes=5)\n",
        "            artist = gr.Label(label=\"Artist\", num_top_classes=5)\n",
        "            movement = gr.Label(label=\"Movement\", num_top_classes=5)\n",
        "            trending = gr.Label(label=\"Trending\", num_top_classes=5)\n",
        "            flavor = gr.Label(label=\"Flavor\", num_top_classes=5)\n",
        "    button = gr.Button(\"Analyze\")\n",
        "    button.click(image_analysis, inputs=image, outputs=[medium, artist, movement, trending, flavor])\n",
        "\n",
        "with gr.Blocks() as ui:\n",
        "    with gr.Tab(\"Prompt\"):\n",
        "        prompt_tab()\n",
        "    with gr.Tab(\"Analyze\"):\n",
        "        analyze_tab()\n",
        "\n",
        "ui.launch(show_api=False, debug=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PvxJsjjhMGaY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.15 ('py37')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "1f51d5616d3bc2b87a82685314c5be1ec9a49b6e0cb1f707bfa2acb6c45f3e5f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}